{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "from utils import plots, get_batches, plot_confusion_matrix, get_data\n",
    "\n",
    "\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR  = '/home/ubuntu/Extracting-food-preferences'\n",
    "PICTURES_DIR = '/home/ubuntu/Extracting-food-preferences/classification_with_pics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR  = 'C:\\\\Users\\\\Natalia\\\\Documents\\\\GitHub\\\\Extracting-food-preferences'\n",
    "PICTURES_DIR = 'C:\\\\Users\\\\Natalia\\\\Documents\\\\GitHub\\\\Extracting-food-preferences\\\\classification_with_pics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Natalia\\Documents\\GitHub\\Extracting-food-preferences\n"
     ]
    }
   ],
   "source": [
    "%cd $PROJECT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $PICTURES_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = PICTURES_DIR #+ '/sample'\n",
    "#path = PICTURES_DIR + '\\\\' + 'sample\\\\'\n",
    "results_path=path + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Natalia\\Documents\\GitHub\\Extracting-food-preferences\\classification_with_pics\n"
     ]
    }
   ],
   "source": [
    "%cd $PICTURES_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = PICTURES_DIR + '\\\\sample\\\\'\n",
    "#path = PICTURES_DIR + '\\\\' + 'sample\\\\'\n",
    "results_path=path + '\\\\results\\\\'\n",
    "train_path=path + '\\\\train\\\\'\n",
    "valid_path=path + '\\\\valid\\\\'\n",
    "\n",
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set constants\n",
    "batch_size=25\n",
    "no_of_epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use batch size of 1 since we're just doing preprocessing on the CPU\n",
    "val_batches = get_batches(path+'valid', shuffle=False, batch_size=10)\n",
    "batches     = get_batches(path+'train', shuffle=False, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['popular\\\\True.recipe-102411041699034.jpg',\n",
       " 'popular\\\\True.recipe-102671041844798.jpg',\n",
       " 'popular\\\\True.recipe-1057321210955840.jpg',\n",
       " 'popular\\\\True.recipe-1088301214749180.jpg',\n",
       " 'popular\\\\True.recipe-1112421217265658.jpg',\n",
       " 'popular\\\\True.recipe-1141581220439774.jpg',\n",
       " 'popular\\\\True.recipe-1190261224856981.jpg',\n",
       " 'popular\\\\True.recipe-119211050673169.jpg',\n",
       " 'popular\\\\True.recipe-1195031225279456.jpg',\n",
       " 'popular\\\\True.recipe-1250081230025580.jpg']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import Vgg16 \n",
    "vgg = Vgg16()\n",
    "model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_features = vgg.predict_gen(batches)\n",
    "val_features = vgg.predict_gen(val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array(model_path+'train_lastlayer_features.bc', trn_features[1])\n",
    "save_array(model_path+'valid_lastlayer_features.bc', val_features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = load_array(model_path+'train_lastlayer_features.bc')\n",
    "val_features = load_array(model_path+'valid_lastlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1000 inputs, since that's the saved features, and 2 outputs, for dog and cat\n",
    "lm = Sequential([ Dense(2, activation='softmax', input_shape=(1000,)) ])\n",
    "lm.compile(optimizer=RMSprop(lr=0.1), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 0s - loss: 0.7219 - acc: 0.5400 - val_loss: 0.7725 - val_acc: 0.4400\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 0s - loss: 0.6346 - acc: 0.6300 - val_loss: 0.7716 - val_acc: 0.4400\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 0s - loss: 0.6086 - acc: 0.6800 - val_loss: 0.8055 - val_acc: 0.4600\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 0s - loss: 0.5720 - acc: 0.7150 - val_loss: 0.8194 - val_acc: 0.4400\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 0s - loss: 0.5654 - acc: 0.7100 - val_loss: 0.8422 - val_acc: 0.5400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18301a19c88>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(trn_features, trn_labels, nb_epoch=5, batch_size=batch_size, \n",
    "       validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_26 (Dense)                 (None, 2)             2002        dense_input_2[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 2,002\n",
      "Trainable params: 2,002\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
