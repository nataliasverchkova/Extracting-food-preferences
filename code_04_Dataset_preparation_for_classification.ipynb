{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import csv\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/recipes_df10-12-2017.csv', error_bad_lines=False, encoding='utf-8', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(df.recipe_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ing_cols = [col for col in df.columns if '_ing' in col]\n",
    "tag_cols = [col for col in df.columns if '_tag' in col]\n",
    "all_cols = df.columns.values.tolist()\n",
    "rest_cols = set(all_cols) - set(ing_cols) - set(tag_cols)\n",
    "rest_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_with_pics = df[df.has_picture == 'yes'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_v = 'recipe_id'\n",
    "dv   = 'printed_per_day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_with_pics[[id_v, dv]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_with_pics = df_with_pics.drop_duplicates(subset=[id_v, dv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(df_with_pics.recipe_id))\n",
    "print(len(set(df_with_pics.recipe_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_with_pics[dv].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_with_pics['label'] = (df_with_pics[dv] >= df_with_pics[dv].quantile(q=0.5)).astype(str)\n",
    "df_with_pics['label'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.exp(df[dv].quantile(q=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.exp(df_with_pics[dv].quantile(q=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pictures into folders with category in their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#current_dir = os.getcwd()\n",
    "PROJECT_DIR = 'C:\\\\Users\\\\Natalia\\\\Documents\\\\GitHub\\\\Extracting-food-preferences'\n",
    "CLASSIFICATION_DIR = PROJECT_DIR + '\\\\classification_with_pics'\n",
    "PICTURES_DIR = PROJECT_DIR + '\\\\pictures\\\\search_pics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $CLASSIFICATION_DIR\n",
    "%mkdir valid\n",
    "%mkdir sample\n",
    "%mkdir results\n",
    "%mkdir -p sample\\train\n",
    "%mkdir -p sample\\valid\n",
    "%mkdir -p sample\\results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# made a renamed copy of pictures\n",
    "# remove images without labels\n",
    "#nl = (set(g) - set(df_with_pics[id_v]+'.jpg'))\n",
    "#g = list(set(g) - set(nl))\n",
    "#for i in range(len(g)): copyfile(g[i], \n",
    "#                                 CLASSIFICATION_DIR + '\\\\train\\\\'+ df_with_pics[df_with_pics[id_v]+'.jpg' == g[i]].label.item() + '.' + g[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set train data folder as a working diretory\n",
    "%cd $CLASSIFICATION_DIR/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# move 30k pictures from training set to validation set\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(30000): os.rename(shuf[i], CLASSIFICATION_DIR+'\\\\valid\\\\' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy 200 images to sample set for experimentation\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(200): copyfile(shuf[i], CLASSIFICATION_DIR+'\\\\sample\\\\train\\\\' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set validation data folder as a working diretory\n",
    "%cd $CLASSIFICATION_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy 50 images from validation set to sample validation\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(50): copyfile(shuf[i], CLASSIFICATION_DIR+'\\\\sample\\\\valid\\\\' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rearrange image files into their respective directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divide cat/dog images into separate directories\n",
    "%cd $CLASSIFICATION_DIR/sample/train\n",
    "%mkdir popular\n",
    "%mkdir unpopular\n",
    "!move True.*.jpg popular/\n",
    "!move False.*.jpg unpopular/\n",
    "\n",
    "%cd $CLASSIFICATION_DIR/sample/valid\n",
    "%mkdir popular\n",
    "%mkdir unpopular\n",
    "!move True.*.jpg popular/\n",
    "!move False.*.jpg unpopular/\n",
    "\n",
    "%cd $CLASSIFICATION_DIR/valid\n",
    "%mkdir popular\n",
    "%mkdir unpopular\n",
    "!move True.*.jpg popular/\n",
    "!move False.*.jpg unpopular/\n",
    "\n",
    "%cd $CLASSIFICATION_DIR/train\n",
    "%mkdir popular\n",
    "%mkdir unpopular\n",
    "!move True.*.jpg popular/\n",
    "!move False.*.jpg unpopular/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Finetune the VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Natalia\\Documents\\GitHub\\Extracting-food-preferences\\classification_with_pics\n"
     ]
    }
   ],
   "source": [
    "%cd $CLASSIFICATION_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = CLASSIFICATION_DIR + '\\\\' + 'sample\\\\'\n",
    "#test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path=path + 'results\\\\'\n",
    "train_path=path + 'train\\\\'\n",
    "valid_path=path + 'valid\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import Vgg16 helper class\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set constants. You can experiment with no_of_epochs to improve the model\n",
    "batch_size=50\n",
    "no_of_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Finetune the model\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "\n",
    "#Not sure if we set this for all fits\n",
    "vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "#Notice we are passing in the validation dataset to the fit() method\n",
    "#For each epoch we test our model against the validation set\n",
    "latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print(\"Running epoch: {}\".format(epoch))\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft{}.h5'.format(epoch)\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "print(\"Completed {} fit operations\".format(no_of_epochs))\n",
    "end = datetime.now()\n",
    "total = end - start\n",
    "print('Time to run the script on CPU is {}'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
